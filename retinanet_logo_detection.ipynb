{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retinanet_logo_detection.ipynb",
      "provenance": [],
      "mount_file_id": "167YMYDck68GBROqJkaXChvWj2IkwBEmz",
      "authorship_tag": "ABX9TyMKIluUOIB5Wllvrgj7p0S5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiebukar/Retinanet_logo_detection/blob/main/retinanet_logo_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyYLv444gXam"
      },
      "source": [
        "# # mount google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_hFAoBg3Dhj"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNLYx7QGnhnJ"
      },
      "source": [
        "# installing retinanet\n",
        "!git clone https://github.com/fizyr/keras-retinanet\n",
        "os.chdir('keras-retinanet')\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am_fboJN4Cqq"
      },
      "source": [
        "# # import required libraries\n",
        "# import keras\n",
        "# import cv2\n",
        "# import keras_retinanet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-bf-dMr4EAy"
      },
      "source": [
        "# # checking retinanent-train command\n",
        "# !retinanet-train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssCM3ipteJYF"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Retinanet/Retinanet_logo_detection')  # redirect worrking dir to base folder\n",
        "\n",
        "# indicate bash command\n",
        "%%bash \n",
        "mkdir -p config   # create config folder\n",
        "touch config/__init__.py # create __init__.py  file\n",
        "touch config/logos_config.py # create logos_config.py  file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un_yvVO84mPf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGgOHR9QhIzz",
        "outputId": "251bcd20-6a06-4096-a823-0dc8fb1874f8"
      },
      "source": [
        "%%writefile config/logos_config.py\n",
        "\n",
        "import os\n",
        "\n",
        "# initiaize the base path to the  dataset\n",
        "BASE_PATH = 'logos'\n",
        "\n",
        "# build the path to the annotations and input images\n",
        "ANNOT_PATH = os.path.sep.join([BASE_PATH, 'annotations'])\n",
        "IMAGES_PATH = os.path.sep.join([BASE_PATH, 'images'])\n",
        "                              \n",
        "# build the path to the training and testing .txt files\n",
        "TRAIN_TXT = os.path.sep.join([BASE_PATH, \"train.txt\"])\n",
        "TEST_TXT = os.path.sep.join([BASE_PATH, \"test.txt\"])\n",
        "\n",
        "# build the path to the training and test .csv files\n",
        "TRAIN_CSV = os.path.sep.join([BASE_PATH, \"retinanet_train.csv\"])\n",
        "TEST_CSV = os.path.sep.join([BASE_PATH, \"retinanet_test.csv\"])\n",
        "\n",
        "# build the path to the output classes CSV file\n",
        "CLASSES_CSV = os.path.sep.join([BASE_PATH, \"retinanet_classes.csv\"])                            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config/logos_config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmh636vJr4hW"
      },
      "source": [
        "# # download and copy the Resnet50_Coco file the logos directory\n",
        "# !wget https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\n",
        "# !mv resnet50_coco_best_v2.1.0.h5 /content/drive/MyDrive/Retinanet/Retinanet_logo_detection/logos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMQK-H9D0vMv",
        "outputId": "330ae1d2-20df-48ff-a353-bc06bf97da02"
      },
      "source": [
        "%%writefile build_logos.py\n",
        "\n",
        "# import the necessary packages\n",
        "from config import logos_config as config\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# initialize the set of classes we have encountered so far\n",
        "CLASSES = set()\n",
        "\n",
        "# create the list of datasets to build\n",
        "datasets = [\n",
        "\t(\"train\", config.TRAIN_TXT, config.TRAIN_CSV),\n",
        "\t(\"test\", config.TEST_TXT, config.TEST_CSV),\n",
        "]\n",
        "\n",
        "# loop over the datasets\n",
        "for (dType, inputTxt, outputCSV) in datasets:\n",
        "\t# load the contents of the input data split\n",
        "\tprint(\"[INFO] starting '{}' set...\".format(dType))\n",
        "\timageIDs = open(inputTxt).read().strip().split(\"\\n\")\n",
        "\tprint(\"[INFO] {} total images in '{}' set\".format(\n",
        "\t\tlen(imageIDs), dType))\n",
        "\n",
        "\t# open the output CSV file\n",
        "\tcsv = open(outputCSV, \"w\")\n",
        "\n",
        "\t# loop over the image IDs\n",
        "\tfor imageID in imageIDs:\n",
        "\t\t# build the path to the image path and annotation file\n",
        "\t\timagePath = \"{}.jpg\".format(os.path.sep.join([\n",
        "\t\t\tconfig.IMAGES_PATH, imageID]))\n",
        "\t\tannotPath = \"{}.xml\".format(os.path.sep.join([\n",
        "\t\t\tconfig.ANNOT_PATH, imageID]))\n",
        "\n",
        "\t\t# load the annotation file, build the soup, and initialize\n",
        "\t\t# the set of coordinates for this particular image\n",
        "\t\tcontents = open(annotPath).read()\n",
        "\t\tsoup = BeautifulSoup(contents, \"html.parser\")\n",
        "\t\tcoords = set()\n",
        "\n",
        "\t\t# extract the image dimensions\n",
        "\t\tw = int(soup.find(\"width\").string)\n",
        "\t\th = int(soup.find(\"height\").string)\n",
        "\n",
        "\t\t# loop over all `object` elements\n",
        "\t\tfor o in soup.find_all(\"object\"):\n",
        "\t\t\t# extract the label and bounding box coordinates\n",
        "\t\t\tlabel = o.find(\"name\").string\n",
        "\t\t\txMin = int(o.find(\"xmin\").string)\n",
        "\t\t\tyMin = int(o.find(\"ymin\").string)\n",
        "\t\t\txMax = int(o.find(\"xmax\").string)\n",
        "\t\t\tyMax = int(o.find(\"ymax\").string)\n",
        "\n",
        "\t\t\t# truncate any bounding box coordinates that may fall\n",
        "\t\t\t# outside the boundaries of the image\n",
        "\t\t\txMin = max(0, xMin)\n",
        "\t\t\tyMin = max(0, yMin)\n",
        "\t\t\txMax = min(w, xMax)\n",
        "\t\t\tyMax = min(h, yMax)\n",
        "\n",
        "\t\t\t# build a (hashable) tuple from the coordinates\n",
        "\t\t\tcoord = (xMin, yMin, xMax, yMax)\n",
        "\n",
        "\t\t\t# if the coordinates already exist in our `coords` set,\n",
        "\t\t\t# ignore the annotation (this is a peculiarity of the\n",
        "\t\t\t# logos dataset)\n",
        "\t\t\tif coord in coords:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t# write the image path, bounding box coordinates, and\n",
        "\t\t\t# label to the output CSV file\n",
        "\t\t\trow = [os.path.abspath(imagePath), str(xMin), str(yMin),\n",
        "\t\t\t\tstr(xMax), str(yMax), label]\n",
        "\t\t\tcsv.write(\"{}\\n\".format(\",\".join(row)))\n",
        "\n",
        "\t\t\t# add the bounding box coordinates to our set and update\n",
        "\t\t\t# the set of class labels\n",
        "\t\t\tcoords.add(coord)\n",
        "\t\t\tCLASSES.add(label)\n",
        "\n",
        "\t# close the output CSV file\n",
        "\tcsv.close()\n",
        "\n",
        "# write the classes to file\n",
        "print(\"[INFO] writing classes...\")\n",
        "csv = open(config.CLASSES_CSV, \"w\")\n",
        "rows = [\",\".join([c, str(i)]) for (i, c) in enumerate(CLASSES)]\n",
        "csv.write(\"\\n\".join(rows))\n",
        "csv.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting build_logos.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEv96IPg0veE",
        "outputId": "35c73f21-6d1a-44f8-bf70-1aec985894b8"
      },
      "source": [
        "# run build_logos.py\n",
        "!python build_logos.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] starting 'train' set...\n",
            "[INFO] 748 total images in 'train' set\n",
            "[INFO] starting 'test' set...\n",
            "[INFO] 187 total images in 'test' set\n",
            "[INFO] writing classes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57hV2NWdpg6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c9327c-1ce3-445f-9a86-1be763385bb1"
      },
      "source": [
        "!wc -l logos/retinanet_train.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1393 logos/retinanet_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ0W6lFFphDG",
        "outputId": "b81f9384-605b-4f4d-dd9f-41c1d7175739"
      },
      "source": [
        "1393//2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "696"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MWxsV1-uWLq"
      },
      "source": [
        "!mkdir logos/snapshots\n",
        "!retinanet-train --batch-size 2 --steps 374 --epochs 28 \\\n",
        "--weights logos/resnet50_coco_best_v2.1.0.h5 \\\n",
        "--snapshot-path logos/snapshots \\\n",
        "csv logos/retinanet_train.csv logos/retinanet_classes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx6Sj6aDX6LP",
        "outputId": "3e4d063d-f613-4db6-fa25-cc2554545695"
      },
      "source": [
        "# export model\n",
        "!retinanet-convert-model logos/snapshots/resnet50_csv_28.h5 output.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-14 18:48:55.321234: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK8fsVSaeHq0",
        "outputId": "e3304c6e-94e7-4ede-d8e5-6efdd64c84f1"
      },
      "source": [
        "!retinanet-evaluate csv logos/retinanet_test.csv \\\n",
        "logos/retinanet_classes.csv output.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model, this may take a second...\n",
            "2021-11-14 18:50:29.438913: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Running network: 100% (187 of 187) |######| Elapsed Time: 0:19:08 Time:  0:19:08\n",
            "Parsing annotations: 100% (187 of 187) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "16 instances of class FC_Barcelona with average precision: 0.6631\n",
            "16 instances of class Audi-Pict with average precision: 0.5307\n",
            "5 instances of class Audi-Text with average precision: 0.0500\n",
            "13 instances of class Facebook-Text with average precision: 0.4491\n",
            "22 instances of class Allianz-Text with average precision: 0.6641\n",
            "25 instances of class Adidas-Pict with average precision: 0.4238\n",
            "23 instances of class FC_Bayern_Munchen with average precision: 0.7873\n",
            "4 instances of class Atletico_Madrid with average precision: 1.0000\n",
            "13 instances of class Amazon with average precision: 0.7981\n",
            "36 instances of class eBay with average precision: 0.6448\n",
            "17 instances of class Burger_king with average precision: 0.8824\n",
            "18 instances of class BMW with average precision: 0.8452\n",
            "1 instances of class Facebook-Pict with average precision: 0.5000\n",
            "23 instances of class Allianz-Pict with average precision: 0.5418\n",
            "12 instances of class Ferrari-Pict with average precision: 0.4766\n",
            "30 instances of class CocaCola with average precision: 0.7744\n",
            "15 instances of class Ferrari-Text with average precision: 0.3272\n",
            "13 instances of class Apple with average precision: 0.8283\n",
            "19 instances of class Aldi with average precision: 0.5102\n",
            "21 instances of class Adidas-Text with average precision: 0.3974\n",
            "Inference time for 187 images: 6.0996\n",
            "mAP using the weighted average of precisions among classes: 0.6197\n",
            "mAP: 0.6047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Dh2sHutLp7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "f0a9542b-0da1-4324-82a2-bbf92f4063cd"
      },
      "source": [
        "!touch predict.py \n",
        "%%writefile predict.py\n",
        "\n",
        "# import the necessary packages\n",
        "from keras_retinanet.utils.image import preprocess_image\n",
        "from keras_retinanet.utils.image import read_image_bgr\n",
        "from keras_retinanet.utils.image import resize_image\n",
        "from keras_retinanet import models\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "\thelp=\"path to pre-trained model\")\n",
        "ap.add_argument(\"-l\", \"--labels\", required=True,\n",
        "\thelp=\"path to class labels\")\n",
        "ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "\thelp=\"path to input image\")\n",
        "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
        "\thelp=\"minimum probability to filter weak detections\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# load the class label mappings\n",
        "LABELS = open(args[\"labels\"]).read().strip().split(\"\\n\")\n",
        "LABELS = {int(L.split(\",\")[1]): L.split(\",\")[0] for L in LABELS}\n",
        "\n",
        "# load the model from disk\n",
        "model = models.load_model(args[\"model\"], backbone_name=\"resnet50\")\n",
        "\n",
        "# load the input image (in BGR order), clone it, and preprocess it\n",
        "image = read_image_bgr(args[\"image\"])\n",
        "output = image.copy()\n",
        "image = preprocess_image(image)\n",
        "(image, scale) = resize_image(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# detect objects in the input image and correct for the image scale\n",
        "(boxes, scores, labels) = model.predict_on_batch(image)\n",
        "boxes /= scale\n",
        "\n",
        "# loop over the detections\n",
        "for (box, score, label) in zip(boxes[0], scores[0], labels[0]):\n",
        "\t# filter out weak detections\n",
        "\tif score < args[\"confidence\"]:\n",
        "\t\tcontinue\n",
        "\n",
        "\t# convert the bounding box coordinates from floats to integers\n",
        "\tbox = box.astype(\"int\")\n",
        "\n",
        "\t# build the label and draw the label + bounding box on the output\n",
        "\t# image\n",
        "\tlabel = \"{}: {:.2f}\".format(LABELS[label], score)\n",
        "\tcv2.rectangle(output, (box[0], box[1]), (box[2], box[3]),\n",
        "\t\t(0, 255, 0), 2)\n",
        "\tcv2.putText(output, label, (box[0], box[1] - 10),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# show the output image\n",
        "cv2.imshow(\"Output\", output)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-2d2d55792641>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    %%writefile predict.py\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiroKnzPtr4G"
      },
      "source": [
        "!python predict.py --model output.h5 --labels logos/retinanet_classes.csv \\\n",
        "--image logos/images/786414.jpg --confidence 0.5"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}